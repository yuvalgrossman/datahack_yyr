{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import section\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from urllib import request\n",
    "import json\n",
    "from sklearn.preprocessing import OneHotEncoder, Normalizer, Binarizer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yama\\docume~1\\datapr~1\\dh_yyr\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_accounts = pd.read_csv(data_path + 'train_accounts.csv')\n",
    "train_users = pd.read_csv(data_path + 'train_users.csv')\n",
    "train_events = pd.read_csv(data_path + 'train_events.csv')\n",
    "train_subscriptions = pd.read_csv(data_path + 'train_subscriptions.csv')\n",
    "test_accounts = pd.read_csv(data_path + 'test_accounts.csv')\n",
    "test_users = pd.read_csv(data_path + 'test_users.csv')\n",
    "test_events = pd.read_csv(data_path + 'test_events.csv')\n",
    "test_subscriptions = pd.read_csv(data_path + 'test_subscriptions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We map our features into different types\n",
    "categorical_features = ['os']\n",
    "normalized_features = ['collection_21_days']\n",
    "binary_features = ['plan_id']\n",
    "untouched_features = ['paying']\n",
    "target = ['lead_score']\n",
    "\n",
    "# And create a column transformer to handle the manipulation for us\n",
    "preprocess = make_column_transformer(\n",
    "    (OneHotEncoder(), categorical_features),\n",
    "    (Normalizer(), normalized_features),\n",
    "    (Binarizer(), binary_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yama\\docume~1\\datapr~1\\dh_yyr\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "train_accounts.set_index('account_id', inplace=True)\n",
    "test_accounts.set_index('account_id', inplace=True)\n",
    "\n",
    "# Getting only the relevant features from the dataset\n",
    "dataset_train = train_accounts[categorical_features + normalized_features + binary_features + untouched_features + target]\n",
    "dataset_test = test_accounts[categorical_features + normalized_features + binary_features + untouched_features]\n",
    "\n",
    "# Filling empty values with default values \n",
    "def fill_empty_values(dataset):\n",
    "    dataset.loc[:,categorical_features] = dataset[categorical_features].fillna('')\n",
    "    dataset.loc[:,normalized_features + binary_features + untouched_features] = dataset[normalized_features + binary_features + untouched_features].fillna(0)\n",
    "    return dataset\n",
    "\n",
    "dataset_train = fill_empty_values(dataset_train)\n",
    "dataset_test = fill_empty_values(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating the label\n",
    "y = dataset_train.pop('lead_score')\n",
    "# We fit our column transformer on both the train and the test sets\n",
    "concatenated = pd.concat([dataset_train, dataset_test])\n",
    "preprocess.fit(concatenated)\n",
    "\n",
    "# We use transform to finally manipulate the features of our training set\n",
    "dataset_train = dataset_train[concatenated.columns]\n",
    "x = preprocess.transform(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yama\\docume~1\\datapr~1\\dh_yyr\\venv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.05, random_state=42)\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not lead       0.98      1.00      0.99     66427\n",
      "        lead       0.00      0.00      0.00      1672\n",
      "\n",
      "    accuracy                           0.98     68099\n",
      "   macro avg       0.49      0.50      0.49     68099\n",
      "weighted avg       0.95      0.98      0.96     68099\n",
      "\n",
      "Acc:  0.9754475102424411\n",
      "MCC: 0.0\n",
      "F1:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yama\\docume~1\\datapr~1\\dh_yyr\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "c:\\users\\yama\\docume~1\\datapr~1\\dh_yyr\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:872: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "c:\\users\\yama\\docume~1\\datapr~1\\dh_yyr\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['not lead','lead']))\n",
    "print('Acc:  {}'.format(metrics.accuracy_score(y_test, y_pred)))\n",
    "print('MCC: {}'.format(metrics.matthews_corrcoef(y_test, y_pred)))\n",
    "print('F1:  {}'.format(metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = dataset_test[concatenated.columns]\n",
    "x_submission = preprocess.transform(dataset_test)\n",
    "y_pred_submission = model.predict(x_submission)\n",
    "# Creating a dictionary where the keys are the account_ids\n",
    "# and the values are your predictions\n",
    "submission_account_ids = test_accounts.index\n",
    "predictions = dict(zip(submission_account_ids, map(int, y_pred_submission)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = 'fRidaY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'member': 'fRidaY', 'rank': 1, 'score': 194854.59630942973}\n"
     ]
    }
   ],
   "source": [
    "# We validate first that we actually send all the test accounts expected to be sent\n",
    "if y_pred_submission.shape[0] != 71683 or submission_account_ids.shape[0] != 71683:\n",
    "  raise Exception(\"You have to send all of the accounts! Expected: (71683, 71683), Got: ({}, {})\".format(y_pred_submission.shape[0], submission_account_ids.shape[0]))\n",
    "\n",
    "if \"group_name\" not in vars() or group_name == \"\":\n",
    "  group_name = input(\"Please enter your group's name:\")\n",
    "\n",
    "data = json.dumps({'submitter': group_name, 'predictions': predictions}).encode('utf-8')\n",
    "\n",
    "req = request.Request(\"https://leaderboard.datahack.org.il/monday/api/\",\n",
    "                      headers={'Content-Type': 'application/json'},\n",
    "                      data=data)\n",
    "\n",
    "res = request.urlopen(req)\n",
    "print(json.load(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
